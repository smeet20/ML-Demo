{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#320088'>Machine Learning Demo - April 5, 2019</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='#00555A'>Kevin Patel <br> Soham Pachpande <br> Smeet Vora</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nbi:hide_in\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn import gaussian_process\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel, RBF\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "import numpy\n",
    "import nbinteract as nbi\n",
    "import seaborn as sns\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#320088'>Gaussian Distribution</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Distributions are a powerful tool for statistical and Machine Learning tasks. They are used in fitting regression models, clustering and much more.\n",
    "A gaussian distribution in a random variable X with mean μ and variance σ is a continuous statistic distribution on domain x∊(-∞,+∞) with probability density function given by the below equation. It is a bell curved shape probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $$p(x \\mid \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma}} \\exp\\left\\{ -\\frac{(x-\\mu)^2}{\\sigma^2}\\right\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#320088'>Visualisation of Gaussian Distribution</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following widget visualises Gaussian Distribution in Single Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a02882184504a9883e15d1430cb518e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='Mu', max=10), FloatSlider(value=7.5, description='Sigma'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#nbi:hide_in\n",
    "def single_g(Mu, Sigma):\n",
    "    \n",
    "    x = numpy.linspace(-2.5, 12.5, 100)\n",
    "    rv = multivariate_normal(Mu, Sigma)\n",
    "    Z = rv.pdf(x)\n",
    "    \n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    \n",
    "    ax1 = fig.add_subplot(111)\n",
    "    ax1.plot(x, Z)\n",
    "    fig.show()\n",
    "    ax1.set_title(\"Normal Distribution\")\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([])\n",
    "single_g = interact(single_g, Mu=(0,10), Sigma=(0.1,15,0.1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many things closely follow a Normal Distribution:\n",
    "1. Heights of people\n",
    "2. Error in Measurement\n",
    "### & Marks on a test!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#320088'>Fitting a single Gaussian</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us generate some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nbi:hide_in\n",
    "def pdf_func_1(x_array, amp, mean, sigma):\n",
    "    return amp*(1/(sigma*(numpy.sqrt(2*numpy.pi))))*(numpy.exp(-((x_array-mean)**2)/((2*sigma)**2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2a5558475045a2aa5c27691f5baab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=75, description='Mean', max=90, min=50), IntSlider(value=15, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#nbi:hide_in\n",
    "def generate_marks(Mean=75,Sigma=15, Noise=5):\n",
    "    # linearly spaced x-axis of 10 values between 1 and 10\n",
    "    x_array = numpy.linspace(1,100,50)\n",
    "\n",
    "    amp1 = 2000\n",
    "    y_array_gauss = pdf_func_1(x_array, amp1, Mean, Sigma)\n",
    "    # creating some noise to add the the y-axis data\n",
    "    y_noise_gauss = numpy.random.normal(0,Noise,50)\n",
    "    y_array_gauss += y_noise_gauss\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.set_ylim(0,150)\n",
    "    ax1.set_title(\"Generating Data\",fontsize = 15)\n",
    "    ax1.scatter(x_array, y_array_gauss)\n",
    "    \n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.set_ylim(0,150)\n",
    "    ax2.set_title(\"Fitting Data\",fontsize = 15)\n",
    "    ax2.scatter(x_array, y_array_gauss)\n",
    "    popt_gauss, pcov_gauss = scipy.optimize.curve_fit(pdf_func_1, x_array, y_array_gauss, p0=[amp1, Mean, Sigma])\n",
    "    gen_norm = pdf_func_1(x_array, popt_gauss[0], popt_gauss[1],popt_gauss[2])\n",
    "    ax2.plot(x_array,gen_norm,'r-')\n",
    "    fig.suptitle('Marks in ML',fontsize = 20)\n",
    "y_ = interact(generate_marks, Mean=(50,90), Sigma=(1,25,1), Noise=(1,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color='#320088'>Fitting a two Gaussian Variables</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nbi:hide_in\n",
    "def pdf_func_2(x_array, amp1, mean1, sigma1, amp2, mean2, sigma2):\n",
    "    return amp1*(1/(sigma1*(numpy.sqrt(2*numpy.pi))))*(numpy.exp(-((x_array-mean1)**2)/((2*sigma1)**2))) + amp2*(1/(sigma2*(numpy.sqrt(2*numpy.pi))))*(numpy.exp(-((x_array-mean2)**2)/((2*sigma2)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff4f6098b8e439ca57b7fd4fe6b53a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=75, description='Mean1', max=90, min=50), IntSlider(value=5, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#nbi:hide_in\n",
    "def fit_marks_2(Mean1=75,Sigma1=5,Mean2=10,Sigma2=15,Noise=5):\n",
    "# linearly spaced x-axis of 10 values between 1 and 10\n",
    "    x_array = numpy.linspace(1,100,50)\n",
    "\n",
    "    amp1 = 1000\n",
    "    amp2 = 1000\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    y_array_gauss = pdf_func_2(x_array, amp1, Mean1, Sigma1, amp2, Mean2, Sigma2)\n",
    "    # creating some noise to add the the y-axis data\n",
    "    y_noise_gauss = numpy.random.normal(0,Noise,50)\n",
    "    y_array_gauss += y_noise_gauss\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.set_ylim(0,150)\n",
    "    ax1.scatter(x_array, y_array_gauss)\n",
    "    ax1.set_title(\"Generating Data\",fontsize = 15)\n",
    "    fig.suptitle('Marks in ML + Marks in DataScience',fontsize = 20)\n",
    "    popt_gauss, pcov_gauss = scipy.optimize.curve_fit(pdf_func_2, x_array, y_array_gauss, p0=[amp1, Mean1, Sigma1,amp2, Mean2, Sigma2])\n",
    "#     pars_1 = popt_2gauss[0:3]\n",
    "#     pars_2 = popt_2gauss[3:6]\n",
    "#     gauss_peak_1 = _1gaussian(x_array, *pars_1)\n",
    "#     gauss_peak_2 = _1gaussian(x_array, *pars_2)\n",
    "    gen_norm1 = pdf_func_1(x_array, popt_gauss[0], popt_gauss[1],popt_gauss[2])\n",
    "    gen_norm2 = pdf_func_1(x_array, popt_gauss[3], popt_gauss[4],popt_gauss[5])\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.set_ylim(0,150)\n",
    "    ax2.set_title(\"Fitting Data\",fontsize = 15)\n",
    "    ax2.plot(x_array, gen_norm1,'r-')\n",
    "    ax2.plot(x_array,gen_norm2,'m-')\n",
    "    ax2.scatter(x_array, y_array_gauss)\n",
    "\n",
    "gen_marks_2 = interact(fit_marks_2, Mean1=(50,90), Sigma1=(1,10,1),Mean2=(50,90), Sigma2=(1,10,1), Noise=(1,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font color='#320088'>Importance of Gaussian Distribution</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}  Z_{\\large n}=\\frac{\\overline{X}-\\mu}{\\sigma / \\sqrt{n}}=\\frac{X_1+X_2+...+X_{\\large n}-n\\mu}{\\sqrt{n} \\sigma}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let X1,X2,...,Xn be i.i.d. random variables with expected value μ<∞ and standard deviation σ. The above expression tends to be standard Normal or <b>Gaussian Distribution</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\\lim_{n \\rightarrow \\infty} P(Z_{\\large n} \\leq x)=\\Phi(x), \\qquad \\textrm{ for all }x \\in \\mathbb{R},\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This property makes Gaussians very useful tool for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23159c2f97f48efa1f5b2571331721a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=50, description='Mean'), IntSlider(value=50, description='Sigma'), IntSl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#nbi:hide_in\n",
    "def lawlargeNumbers(Mean,Sigma,Samples):\n",
    "    data = norm.rvs(Mean, Sigma, Samples)\n",
    "    mu, std = norm.fit(data)\n",
    "    plt.hist(data, bins=100, density=True, alpha=0.6, color='b')\n",
    "    xmin, xmax = plt.xlim()\n",
    "    x = numpy.linspace(xmin, xmax, 100)\n",
    "    p = norm.pdf(x, mu, std)\n",
    "    plt.plot(x, p, 'k', linewidth=2,color='r')\n",
    "    title = \"Fit Results: Mean = %.2f,  Sigma = %.2f\" % (mu, std)\n",
    "    plt.ylim(0,0.01)\n",
    "    plt.xlim(-200,200)\n",
    "    plt.title(\"Impact of Sampling\",fontsize = 20)\n",
    "    plt.show()\n",
    "t = interact(lawlargeNumbers, Mean=(0,100),Sigma=(0,100), Samples=(1,10000));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#320088'>Multivariate Gaussian Variables</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability distribution function for multivariate gaussian distribution in given by the bellow expression. Here μ is a vector of means of normal distribution in every dimension and Σ is the covariance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p(x \\mid \\mu, \\Sigma) = (2\\pi)^{-k/2}|\\Sigma|^{-1/2} \\exp\\left\\{ -\\frac{1}{2} (x-\\mu)^{\\prime}\\Sigma^{-1}(x-\\mu) \\right\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#320088'>Visualisation of Gaussian Distribution for 2 variables</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b30812512045a28ef51ec42723ef2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='Mean1', max=10), IntSlider(value=5, description='Mean2',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#nbi:hide_in\n",
    "def f(Mean1,Mean2,Cov11=1,Cov12=0,Cov21=0,Cov22=1):\n",
    "    \n",
    "    try: \n",
    "        Cov11=float(Cov11)\n",
    "        Cov12=float(Cov12)\n",
    "        Cov21=float(Cov21)\n",
    "        Cov22=float(Cov22)\n",
    "    except:\n",
    "        print(\"Invalid Covariance Values\")\n",
    "        return\n",
    "    \n",
    "    x = numpy.linspace(0, 10, 100)\n",
    "    y = numpy.linspace(0, 10, 100)\n",
    "    X, Y = numpy.meshgrid(x, y)\n",
    "    pos = numpy.dstack((X, Y))\n",
    "    mu = numpy.array([Mean1,Mean2])\n",
    "    try:\n",
    "        cov = numpy.array([[Cov11, Cov12],[Cov21, Cov22]])\n",
    "        rv = multivariate_normal(mu, cov)\n",
    "        Z = rv.pdf(pos)\n",
    "    except:\n",
    "        print(\"Invalid Covariance Matrix: Not a positive semi-definite Matrix\\nPlease try other values\")\n",
    "        return\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,8))\n",
    "    \n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    ax1.plot_surface(X, Y, Z, cmap='RdPu')\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.contourf(X,Y,Z,levels=25,cmap='RdPu')\n",
    "    \n",
    "    ax1.set_title(\"Probability Distribution Function\")\n",
    "    ax2.set_title(\"Contour Plot\")\n",
    "    \n",
    "    ax2.set_axis_off()\n",
    "    ax1.set_axis_off()\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_zticks([])\n",
    "\n",
    "t = interact(f, Mean1=(0,10),Mean2=(0,10), Cov11='5',Cov12='0',Cov21='0',Cov22='5');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that Gaussian Distributions can be used to model data in above examples.<br> But the Data is not always so straightforward. And Normal distributions are not flexible enough distributions to fit complex data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In such cases, using a set of Gaussian distributions to model data has a number of advantages. \n",
    "1. The Marginal Distribution of any subset of elements from a Multivariate Normal Distribution is also normal<br>\n",
    "$$p(x,y) = \\mathcal{N}\\left(\\left[{ \n",
    "\\begin{array}{c} \n",
    "{\\mu_x} \\\\ \n",
    "{\\mu_y} \\\\ \n",
    "\\end{array} \n",
    "}\\right], \\left[{ \n",
    "\\begin{array}{cc} \n",
    "{\\Sigma_x} & {\\Sigma_{xy}} \\\\\\\\ \n",
    "{\\Sigma_{xy}^T} & {\\Sigma_y} \n",
    "\\end{array} \n",
    "}\\right]\\right)$$<br>\n",
    "$$p(x) = \\int p(x,y) dy = \\mathcal{N}(\\mu_x, \\Sigma_x)$$\n",
    "2. The Conditional Distributions of a subset of the elements of a Multivariate Normal Distribution (conditional on the remaining elements) are normal too:\n",
    "$$p(x|y) = \\mathcal{N}(\\mu_x + \\Sigma_{xy}\\Sigma_y^{-1}(y-\\mu_y), \n",
    "\\Sigma_x-\\Sigma{xy}\\Sigma_y^{-1}\\Sigma{xy}^T)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us formally Define Gaussian Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Process is an infinite collection of Random Variables with any marginal subset having Gaussian distribution. Another way of thinking about an infinite collection or vector of random variables is a function.<br>\n",
    "So a Gaussian process can be described as an distribution over functions and is fully specified by a <b>Mean</b> function and <b>Covariance</b> function\n",
    "$$p(x) \\sim \\mathcal{GP}(m(x), k(x,x^{\\prime}))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things easier we assume the mean function to be <b>zero</b>.\n",
    "Covariance function is also known as kernel. Scikit-Learn and GPflow distributions offer various kernels. Some of these are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Radial Basis Function\n",
    "2. Matern covariance function\n",
    "3. Linear Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regression tasks, GaussianProcessRegressor can be used from scikit-learn by specifying appropriate covariance function or kernel. The GaussianProcessRegressor does not allow for the specification of mean function and always assumes it to be zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting starts by maximizing the marginal likelihood. This is a convinent approach for Gaussian Process as it avoids the computationally expensive cross validation step that is generally used for selecting optimal hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A kernel can be defined as the sum of a covariance function, an amplitude factor(ConstantKernel) and an observational noise(WhiteKernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a114d0017a874460a1db408294847826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='Noise', max=2.0, step=0.5), FloatSlider(value=1.5, d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#nbi:hide_in\n",
    "kernel = WhiteKernel(noise_level=1)+ ConstantKernel() + RBF() #+ Matern(length_scale=2, nu=3/2) \n",
    "\n",
    "x = numpy.linspace(-5,5,101)\n",
    "def gp_fit(Noise, Parameter1, Parameter2):\n",
    "    y = 5+ 5*(numpy.sin(x) + numpy.sin(Parameter1*x+numpy.pi/(Parameter2*2)) - numpy.sin((Parameter1-1)*x+numpy.pi/(Parameter2*4))) + numpy.random.normal(0,Noise,x.shape)\n",
    "\n",
    "    X = x.reshape(-1, 1)\n",
    "    X.shape\n",
    "\n",
    "    gp = gaussian_process.GaussianProcessRegressor(kernel=kernel)\n",
    "    gp.fit(X, y)\n",
    "\n",
    "    x_pred = numpy.linspace(-6, 6).reshape(-1,1)\n",
    "    y_pred, sigma = gp.predict(x_pred, return_std=True)\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.regplot(x, y, fit_reg=False, label='Data')\n",
    "    plt.plot(x_pred, y_pred, color='grey', label='Prediction')\n",
    "    plt.fill(numpy.concatenate([x_pred, x_pred[::-1]]),\n",
    "             numpy.concatenate([y_pred - 2*sigma,\n",
    "                            (y_pred + 2*sigma)[::-1]]),\n",
    "             alpha=.5, fc='grey', ec='None', label='95% CI')\n",
    "    plt.xlabel('$x$')\n",
    "    plt.ylabel('$f(x)$')\n",
    "    plt.xlim(-6, 6)\n",
    "    plt.legend(loc='lower left');\n",
    "    \n",
    "t = interact(gp_fit, Noise=(0,2,0.5),Parameter1=(0.5,2.5,0.1),Parameter2=(2,8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Github link: https://github.com/smeet20/ML-Demo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
